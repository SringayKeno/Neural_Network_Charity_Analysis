# Neural_Network_Charity_Analysis

### Create a deep robust neural network capable of interpreting large complext datasets

## Overview of Analysis

The nonprofit organization, Alphabet Soup, is a philanthropic foundation dedicated to helping organizations protect the environment, improve peoples well being and unify the world. Alphabet Soup has raised and donated over 10 Billion dollars in the last 20 years. This money has been used in life saving technologies and organizing reforestation groups. 

Beks, a data analyst is in charge of data collection and analyzation for Alphabet Soup. Beks job is to analye the impact of each donation and vet potential recepiants. This insures the foundations dollars are being spent effectivatly. Unfortunatly not ever donation Alaphabet Soup makes is impactful. Some organizations receive money only to disappear. 

Senior leadership at Alaphabet Soup has asked Beks to predict which organizations are worth donating too and which are high risk. Alphabet Soup's leadership has asked Bek and her analytics team to produce a mathmatical data driven solution that can do this accurately. Beks has decided this problem is to complex for statistical and machine learning models she has used in the past. Instead Beks will design and train a deep learning neural network. This model will evalutate all types of input data and produce a clear decision making result. 

I will assist Beks in learning about neural networks and how to design and train these models using the Python tensorflow library. I will rely on my past statistics and machine learning experience to help test and opptimize the our models.

With knowledge of machine learning and neural networks, I will use the features in the provided dataset to help Beks create a binary classifier that is capable of predicting whether applicants will be successful if funded by Alphabet Soup.


## Results

Data Preprocessing
What variable(s) are considered the target(s) for your model?
What variable(s) are considered to be the features for your model?
What variable(s) are neither targets nor features, and should be removed from the input data?
Compiling, Training, and Evaluating the Model
How many neurons, layers, and activation functions did you select for your neural network model, and why?
Were you able to achieve the target model performance?
What steps did you take to try and increase model performance?

## Summary

Summarize the overall results of the deep learning model. Include a recommendation 
for how a different model could solve this classification problem, and explain your recommendation.
